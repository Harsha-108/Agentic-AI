# ğŸ¤– Multi-Agent POC Backend

A proof-of-concept multi-agent conversational backend that connects local AI agents with external WebSocket servers. Features intelligent routing, LLM-powered responses, and seamless integration with external systems.

## âœ¨ Key Features

- **ğŸ§  Multi-Agent Intelligence**: Specialized agents for fitness (Helios ğŸ’ª) and nutrition (Ceres ğŸ¥—)
- **ğŸ”— External WebSocket Bridge**: Connect to any external WebSocket server
- **ğŸš€ Real-time Communication**: WebSocket-based chat with typing indicators
- **ğŸ“Š Intelligent Routing**: LLM-powered intent classification with fallback strategies
- **ğŸ“ Context Storage**: File-based conversation and data persistence
- **ğŸ”„ Bidirectional Integration**: Your agents can read and respond to external messages
- **âš¡ High Performance**: Async architecture with load testing capabilities

## ğŸ¯ What You Get

### Local Multi-Agent System
- **WebSocket Server**: Real-time chat interface at `ws://localhost:8000/ws/{user_id}`
- **REST API**: Health checks, session management, file access
- **Agent Ecosystem**: 3 specialized AI agents with distinct personalities
- **Smart Routing**: Keywords + LLM classification for accurate intent detection

### External Integration
- **WebSocket Bridge**: Connect to servers hosted on Render, Heroku, etc.
- **Message Processing**: External messages â†’ Your agents â†’ Responses back
- **Conversation Logging**: All interactions saved to readable files
- **Status Monitoring**: Real-time connection health and metrics

### Testing Suite
- **Load Testing**: Concurrent connection testing with performance metrics
- **External Monitor**: Python client for monitoring external connections
- **Browser Clients**: Ready-to-use HTML test interfaces
- **Health Checks**: Comprehensive system status endpoints

## ğŸš€ Quick Start

### 1. Clone and Setup
```bash
git clone <your-repo>
cd multi-agent-poc
chmod +x run.sh
```

### 2. Configure Environment
```bash
# Edit .env file with your OpenAI API key
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# Optional: External WebSocket connection
EXTERNAL_WS_URL=wss://your-friend-server.onrender.com/ws
EXTERNAL_WS_USER_ID=poc-backend
```

### 3. Start Everything
```bash
./run.sh
```

That's it! The script handles:
- âœ… Virtual environment setup
- âœ… Dependency installation
- âœ… Configuration validation
- âœ… Server startup on `http://localhost:8000`

## ğŸ§ª Testing Your Setup

### Local Agents Test
1. Open `clients/test_local_client.html` in your browser
2. Connect with any user ID
3. Try these messages:
   - "I want to start working out" â†’ Routes to Helios ğŸ’ª
   - "What should I eat for breakfast?" â†’ Routes to Ceres ğŸ¥—
   - "Hello! What can you help with?" â†’ Routes to General Assistant ğŸ¤–

### External Connection Test
1. Open `clients/test_external_client.html`
2. Enter an external WebSocket URL
3. Send test messages and watch for agent responses

### Load Testing
```bash
./run.sh test  # Run load test with 5 clients for 10 seconds
```

## ğŸ“¡ External WebSocket Integration

### How It Works
```
External Server â†’ Your POC Backend â†’ Agent Processing â†’ Response Back
     â†“                   â†“                   â†“              â†“
[User Message]    [Intent Analysis]   [LLM Response]  [External User]
```

### Configuration
```bash
# In .env file
EXTERNAL_WS_URL=wss://friends-app.onrender.com/ws/{user_id}
EXTERNAL_WS_USER_ID=my-poc-client
```

### Automatic Processing
- External messages are automatically routed to appropriate agents
- Responses sent back through the same WebSocket connection
- All interactions logged to `user_contexts/external-socket-user/`

## ğŸ—ï¸ Architecture

### Project Structure
```
Agent_Workflow/
â”œâ”€â”€ app/                    # Main backend application
â”‚   â”œâ”€â”€ main.py            # FastAPI server + WebSocket
â”‚   â”œâ”€â”€ agents.py          # AI agent implementations
â”‚   â”œâ”€â”€ router.py          # Message routing logic
â”‚   â”œâ”€â”€ llm_service.py     # OpenAI integration
â”‚   â”œâ”€â”€ file_service.py    # Context storage
â”‚   â”œâ”€â”€ external_bridge.py # External WebSocket bridge
â”‚   â””â”€â”€ models.py          # Data models
â”œâ”€â”€ clients/               # Test clients and tools
â”‚   â”œâ”€â”€ test_local_client.html    # Local WebSocket client
â”‚   â”œâ”€â”€ test_external_client.html # External connection client
â”‚   â”œâ”€â”€ external_monitor.py       # Python monitoring tool
â”‚   â””â”€â”€ load_test.py              # Load testing script
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ user_contexts/         # User data storage
â””â”€â”€ run.sh                # Quick start script
```

### Agent System
```
MessageRouter
     â”œâ”€â”€ Keyword Analysis (fast routing)
     â”œâ”€â”€ LLM Classification (complex queries)
     â””â”€â”€ Confidence Scoring (0.0-1.0)
           â†“
    Agent Selection
     â”œâ”€â”€ Helios ğŸ’ª (fitness, exercise, workouts)
     â”œâ”€â”€ Ceres ğŸ¥— (nutrition, food, meals)
     â””â”€â”€ General ğŸ¤– (greetings, coordination)
           â†“
    Response Generation
     â”œâ”€â”€ LLM Processing (GPT-4o-mini)
     â”œâ”€â”€ Tool Execution (data storage/retrieval)
     â””â”€â”€ Context Logging (file storage)
```

## ğŸ”§ API Reference

### WebSocket Connection
```javascript
const ws = new WebSocket('ws://localhost:8000/ws/your-user-id');

// Send message
ws.send(JSON.stringify({
    type: "message",
    message: "I want to work out",
    timestamp: new Date().toISOString()
}));
```

### REST Endpoints
- `GET /` - Server info
- `GET /health` - Health status + metrics
- `GET /external-status` - External connection status
- `POST /send-to-external` - Send message to external WebSocket
- `GET /user/{user_id}/files` - List user context files

### Key Features
- **Auto-reconnection**: External WebSocket connections automatically reconnect
- **Error Handling**: Graceful fallbacks for LLM and connection failures
- **Conversation Memory**: Persistent context across sessions
- **Multi-format Support**: JSON and plain text message handling

## ğŸ“Š Performance

### Tested Capabilities
- âœ… **Concurrent Connections**: 50+ simultaneous WebSocket connections
- âœ… **Response Times**: <2s for complex LLM queries, <200ms for simple routing
- âœ… **External Integration**: Stable connections to Render/Heroku hosted servers
- âœ… **Message Throughput**: 100+ messages/minute per agent
- âœ… **Context Storage**: Handles 1000+ conversation entries per user

### Load Testing Results
```bash
python clients/load_test.py --clients 10 --duration 30

# Example Output:
ğŸ“Š LOAD TEST RESULTS
==================
ğŸ¯ Test Configuration:
   Clients: 10
   Duration: 30s
   Server: ws://localhost:8000

ğŸ“ˆ Results Overview:
   Messages Sent: 150
   Messages Received: 148
   Success Rate: 98.67%
   Messages/Second: 5.00
   Total Errors: 2

â±ï¸ Response Times:
   Average: 0.856s
   Median: 0.734s
   95th Percentile: 1.234s
```

## ğŸ› ï¸ Customization

### Adding New Agents
1. Create agent class in `app/agents.py`:
```python
class NewAgent(BaseAgent):
    def __init__(self, file_service, llm_service):
        system_prompt = "You are a helpful agent for..."
        super().__init__("NewAgent", system_prompt, file_service, llm_service)
```

2. Update router in `app/router.py`
3. Add to main server in `app/main.py`

### Custom Tools
```python
async def custom_tool(self, user_id: str, args: Dict) -> str:
    # Your custom logic here
    await self.file_service.save_json(user_id, "custom_data.json", args)
    return "Custom action completed!"
```

### External Integrations
The bridge can connect to any WebSocket server:
- Discord bots
- Slack apps  
- Custom chat applications
- IoT device interfaces
- Game servers

## ğŸš¨ Troubleshooting

### Common Issues

**"No module named 'openai'"**
```bash
source venv/bin/activate
pip install -r requirements.txt
```

**"OpenAI API key not configured"**
- Edit `.env` file with your API key from https://platform.openai.com/api-keys

**External WebSocket connection fails**
- Check URL format: `wss://` for HTTPS, `ws://` for HTTP
- Verify the external server is running and accepts connections
- Check firewall/network restrictions

**Load test shows high error rates**
- Reduce concurrent clients: `--clients 5`
- Check server resources (CPU/memory)
- Verify OpenAI API rate limits

### Debug Commands
```bash
# Check server health
curl http://localhost:8000/health

# Monitor external connections
python clients/external_monitor.py wss://external-server.com/ws

# View logs
tail -f user_contexts/*/conversations.md

# Clean restart
./run.sh clean && ./run.sh
```

## ğŸ“ˆ Next Steps

### Production Enhancements
- [ ] Add authentication (JWT tokens)
- [ ] Implement rate limiting
- [ ] Add Redis for session storage
- [ ] Set up monitoring/logging (Prometheus, Grafana)
- [ ] Add HTTPS/WSS support
- [ ] Database integration (PostgreSQL)

### Feature Extensions  
- [ ] Voice integration (speech-to-text)
- [ ] Image analysis capabilities
- [ ] Multi-language support
- [ ] Advanced agent personalities
- [ ] Integration with external APIs (calendar, weather)
- [ ] Mobile app connectivity

### Advanced Use Cases
- [ ] **Customer Support**: Multi-agent customer service system
- [ ] **Educational Platform**: Subject-specific tutoring agents
- [ ] **Healthcare**: Symptom checker + specialist routing
- [ ] **E-commerce**: Product recommendation + support agents
- [ ] **Gaming**: NPC dialogue systems with personality

## ğŸ¤ Contributing

This is a POC template designed for customization. Fork it and build your own multi-agent system!

### Development Setup
```bash
git clone <your-fork>
cd multi-agent-poc
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt -r requirements-dev.txt
```

### Running Tests
```bash
# Unit tests
python -m pytest tests/

# Integration tests  
python clients/load_test.py --clients 5 --duration 10

# External connectivity tests
python clients/external_monitor.py ws://localhost:8000
```

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ™ Acknowledgments

- OpenAI for GPT-4o-mini
- FastAPI for the excellent async web framework
- WebSockets library for reliable connections
- The open-source community for inspiration

---

**Ready to build your multi-agent system?** Start with `./run.sh` and begin chatting with your AI agents in minutes! ğŸš€